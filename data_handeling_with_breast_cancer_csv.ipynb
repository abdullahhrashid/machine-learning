{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP4jny4ScA9-"
      },
      "outputs": [],
      "source": [
        "#learning how dataset and dataloader works"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "P-KhH033cGC6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self,features,labels):\n",
        "        self.features=features\n",
        "        self.labels=labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.features[index],self.labels[index]\n"
      ],
      "metadata": {
        "id": "ocAkDb_hcK8m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data\n",
        "df = pd.read_csv('breast-cancer.csv')\n",
        "\n",
        "x = df.drop(columns=['id','diagnosis'])\n",
        "x = np.array(x,dtype=np.float32)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['diagnosis'])\n",
        "y = np.array(y)\n",
        "\n",
        "#splitting dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#normalizing data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#converting to tensors\n",
        "X_train = torch.tensor(X_train)\n",
        "Y_train = torch.tensor(y_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "Y_test = torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "S-JXJz07hpr0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using classes\n",
        "\n",
        "#making the dataset\n",
        "dataset = CustomDataset(X_train,Y_train)\n",
        "\n",
        "#creating the dataloader\n",
        "dataloader = DataLoader(dataset,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "dVOAktaviB6a"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model(nn.Module):\n",
        "\n",
        "    def __init__(self,input,output):\n",
        "        super().__init__()\n",
        "        self.layer1=nn.Linear(input,16)\n",
        "        self.layer2=nn.Linear(16,8)\n",
        "        self.layer3=nn.Linear(8,4)\n",
        "        self.layer4=nn.Linear(4,output)\n",
        "\n",
        "    def forward(self,X):\n",
        "        out=F.relu(self.layer1(X))\n",
        "        out=F.relu(self.layer2(out))\n",
        "        out=F.relu(self.layer3(out))\n",
        "        return self.layer4(out)\n",
        "\n",
        "#hyperparameters\n",
        "net = model(30,2)\n",
        "n_epochs=100\n",
        "learning_rate=0.01\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(net.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "b8ok-dNakG3g",
        "collapsed": true
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    for batch_x,batch_y in dataloader:\n",
        "        y_hat=net(batch_x)\n",
        "        l=loss(y_hat,batch_y)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1)%10==0:\n",
        "            print(f\"Epoch [{epoch+1}], Loss: {l.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "smFHthLkTXaP",
        "outputId": "0c0a9945-56d6-4225-f1f3-6c29298b3d6d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10], Loss: 0.0000\n",
            "Epoch [20], Loss: 0.0000\n",
            "Epoch [30], Loss: 0.0000\n",
            "Epoch [40], Loss: 0.0000\n",
            "Epoch [50], Loss: 0.0000\n",
            "Epoch [60], Loss: 0.0000\n",
            "Epoch [70], Loss: 0.0000\n",
            "Epoch [80], Loss: 0.0000\n",
            "Epoch [90], Loss: 0.0000\n",
            "Epoch [100], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation for training set\n",
        "net.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = net(X_train)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == Y_train).sum().item()\n",
        "    total = Y_train.size(0)\n",
        "\n",
        "    print(f\"Training Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjIMSclCcHxq",
        "outputId": "aba35b5b-bcf8-47b9-a38c-301e4e1d32f4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation for test set\n",
        "net.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = net(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == Y_test).sum().item()\n",
        "    total = Y_test.size(0)\n",
        "\n",
        "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkk27CMTXyc8",
        "outputId": "c3c970ae-f57d-4bf3-faf7-6fb634c34d54"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.37%\n"
          ]
        }
      ]
    }
  ]
}